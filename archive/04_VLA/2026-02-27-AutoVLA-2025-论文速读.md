---
date: 2026-02-27
keywords: [AutoVLA, RL, GRPO, Dual-thinking, Fast-Slow Reasoning, 2025]
tags: [Level-04, Perception-Hardcore, RL-Fine-tuning]
---

# AutoVLA-论文速读

## 0. 基本信息
- **发表时间**: 2025年
- **作者单位**: UCLA (加州大学洛杉矶分校)
- **代码仓库**: [https://github.com/ucla-vcl/AutoVLA](https://github.com/ucla-vcl/AutoVLA)
- **Tags**: #GRPO强化学习 #快慢思考 #自适应推理 #VLA

---

## 1. 🔪 今日锐评
> **AutoVLA** 真正让大模型学会了“偷懒”——这在实时驾驶中是神技。
> 
> **核心洞察**：如果前方是一马平川的直线，为什么还要费劲思考 CoT？AutoVLA 提出了 **Dual-thinking (快慢思考)** 机制。通过 **GRPO**（群体相对策略优化）强化学习，模型学会了在简单工况下直接出轨迹（快思考），在复杂工况下才开启昂贵的 LLM 推理（慢思考）。这让模型的整体运行效率提升了 **67%**。

---

## 3. 💡 核心创新 (Math & Pseudo-code)

### 3.1 GRPO 群体相对策略优化
**物理逻辑**：不需要一个单独的 Critic 网络，而是让一组候选样本互相 PK。
**奖励函数**:
$$r_{acc} = \exp( - 	ext{Planning\_Error} ) - 	ext{Collision\_Penalty} - 	ext{Computational\_Cost\_Penalty}$$

---

## 10. 🛠️ 落地建议
- **策略动态调整**: 在量产部署时，建议根据车载 SoC 的实时负载动态调整“慢思考”的阈值，确保在极限工况下系统不卡顿。
